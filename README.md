Mentor: https://github.com/hkproj/

Discord : https://discord.gg/4Tg4TkJQzE

Instructions: https://github.com/hkproj/100-days-of-cuda

# 100 Days of CUDA Learning

This repository documents my 100-day journey of learning CUDA programming, writing optimized kernels, and improving GPU performance.

| Day  | Output Summary | Notes | Link |
|------|--------------|-------|------|
| 1    |  [Vector Addition Kernel](https://github.com/ShlokVFX/100-days-cuda/blob/main/Day%2001/Output.png)  | Learned basic CUDA syntax and kernel execution - Vector Addtion and printing Hello Cuda. | [Day 1](https://github.com/ShlokVFX/100-days-cuda/blob/main/Day%2001/Readme.md) |
| 2    | [Benchmarking Vector Add](https://github.com/ShlokVFX/100-days-cuda/blob/main/Day%2002/BenchmarkVectorAdd.png) | Explored thread indexing and grid-block mapping. | [Day 2](https://github.com/ShlokVFX/100-days-cuda/blob/main/Day%2002/Readme.md) |
| 3    |  [Cuda Streams](https://github.com/ShlokVFX/100-days-cuda/blob/main/Day%2003/CudaStreams_result.png) [AtomicAddtion](https://github.com/ShlokVFX/100-days-cuda/blob/main/Day%2003/AtomicAdditionResult.png) | Improved memory access using shared memory. | [Day 3](https://github.com/ShlokVFX/100-days-cuda/blob/main/Day%2003/Readme.md) |
| 4    | Memory Coalescing Experiment | Optimized global memory access patterns. | [Day 4](./day4/) |
| 5    | Reduction Kernel | Implemented parallel reduction with warp shuffle. | [Day 5](./day5/) |


## Goals:
- Understand CUDA fundamentals.
- Write optimized and efficient GPU kernels.
- Explore memory hierarchy, warp scheduling, and Tensor Cores.
- Apply CUDA to deep learning and high-performance computing.

